{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNI/NCJTaaS8pNLUffCm8qh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohandawar/pyspark/blob/main/RandomForestClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, I am trying to implment Random Forest Classifier in Pyspark"
      ],
      "metadata": {
        "id": "8LokSMCV4ENn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-_hORqi3xQj",
        "outputId": "c0e9c912-725f-4ec0-856f-3791e2b8a711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285398 sha256=ce62af3700051585c900e461632a30d57ca454c9016afab1272f1e5f91f6679d\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the libs\n",
        "\n",
        "# Pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Colab\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "psm4kfth4KkU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a spark session\n",
        "spark = SparkSession.builder.appName('RandomForestClassifier').getOrCreate()"
      ],
      "metadata": {
        "id": "xJsgiyDk4YoC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4AbNMBm4h4H",
        "outputId": "e7b625b8-4f20-4a6a-d3be-c840ed94e9ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read the data\n",
        "df = spark.read.csv('/content/drive/MyDrive/DataSets_Pyspark_GoogleColab_Primer/glassClass.csv', inferSchema=True, header=True)\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvgxvORU4t3A",
        "outputId": "3f48415a-83e8-4013-e0d1-337d3f4bc349"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----+----+-----+----+----+---+---+----+\n",
            "|     RI|   Na|  Mg|  Al|   Si|   K|  Ca| Ba| Fe|Type|\n",
            "+-------+-----+----+----+-----+----+----+---+---+----+\n",
            "|1.52101|13.64|4.49| 1.1|71.78|0.06|8.75|0.0|0.0|   1|\n",
            "|1.51761|13.89| 3.6|1.36|72.73|0.48|7.83|0.0|0.0|   1|\n",
            "|1.51618|13.53|3.55|1.54|72.99|0.39|7.78|0.0|0.0|   1|\n",
            "|1.51766|13.21|3.69|1.29|72.61|0.57|8.22|0.0|0.0|   1|\n",
            "|1.51742|13.27|3.62|1.24|73.08|0.55|8.07|0.0|0.0|   1|\n",
            "+-------+-----+----+----+-----+----+----+---+---+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the class distribution\n",
        "df.groupBy('Type').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukqdRvMo47_7",
        "outputId": "49806e01-af2a-4afd-fa2b-cb1cebd3abd2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|Type|count|\n",
            "+----+-----+\n",
            "|   1|   70|\n",
            "|   6|    9|\n",
            "|   3|   17|\n",
            "|   5|   13|\n",
            "|   7|   29|\n",
            "|   2|   76|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col_list = df.columns\n",
        "print('All columns Names:', col_list)\n",
        "col_list.remove('Type')\n",
        "print(' columns Names post remove of the Target Variable:', col_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6isiP-nb5jJi",
        "outputId": "0bcef56c-4313-40dd-f99c-55e8159802d7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All columns Names: ['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type']\n",
            " columns Names post remove of the Target Variable: ['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Insitiate the vector Assembler\n",
        "vec_assembler = VectorAssembler(inputCols=col_list, outputCol='features')\n",
        "\n",
        "finaldf = vec_assembler.transform(df)\n",
        "finaldf.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iss4PuCj5KAp",
        "outputId": "0764786b-6a76-49c6-b70b-9ac66b889347"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----+----+-----+----+----+---+---+----+--------------------+\n",
            "|     RI|   Na|  Mg|  Al|   Si|   K|  Ca| Ba| Fe|Type|            features|\n",
            "+-------+-----+----+----+-----+----+----+---+---+----+--------------------+\n",
            "|1.52101|13.64|4.49| 1.1|71.78|0.06|8.75|0.0|0.0|   1|[1.52101,13.64,4....|\n",
            "|1.51761|13.89| 3.6|1.36|72.73|0.48|7.83|0.0|0.0|   1|[1.51761,13.89,3....|\n",
            "|1.51618|13.53|3.55|1.54|72.99|0.39|7.78|0.0|0.0|   1|[1.51618,13.53,3....|\n",
            "|1.51766|13.21|3.69|1.29|72.61|0.57|8.22|0.0|0.0|   1|[1.51766,13.21,3....|\n",
            "|1.51742|13.27|3.62|1.24|73.08|0.55|8.07|0.0|0.0|   1|[1.51742,13.27,3....|\n",
            "+-------+-----+----+----+-----+----+----+---+---+----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train & Test Split\n",
        "train_df, test_df = finaldf.randomSplit([0.7,0.3], seed=42)"
      ],
      "metadata": {
        "id": "aOIz-b986ls6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instiate the model\n",
        "rf = RandomForestClassifier(featuresCol='features', labelCol='Type')\n",
        "\n",
        "# Fit the model on training data\n",
        "rf_model = rf.fit(train_df)"
      ],
      "metadata": {
        "id": "cRbqPYP063ye"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Predictions\n",
        "pred_df = rf_model.transform(test_df)\n",
        "pred_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1bMV1927JMp",
        "outputId": "ad54c84c-b68b-4db1-96be-a66886713a1e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----+----+-----+----+----+----+----+----+--------------------+--------------------+--------------------+----------+\n",
            "|     RI|   Na|  Mg|  Al|   Si|   K|  Ca|  Ba|  Fe|Type|            features|       rawPrediction|         probability|prediction|\n",
            "+-------+-----+----+----+-----+----+----+----+----+----+--------------------+--------------------+--------------------+----------+\n",
            "|1.51215|12.99|3.47|1.12|72.98|0.62|8.35| 0.0|0.31|   1|[1.51215,12.99,3....|[0.0,4.1341852770...|[0.0,0.2067092638...|       2.0|\n",
            "|1.51409|14.25|3.09|2.08|72.28| 1.1|7.08| 0.0| 0.0|   2|[1.51409,14.25,3....|[0.0,1.3225274725...|[0.0,0.0661263736...|       7.0|\n",
            "|1.51514|14.01|2.68| 3.5|69.89|1.68|5.87| 2.2| 0.0|   5|[1.51514,14.01,2....|[0.0,1.0,3.0,0.0,...|[0.0,0.05,0.15,0....|       7.0|\n",
            "|1.51514|14.85| 0.0|2.42|73.72| 0.0|8.39|0.56| 0.0|   7|[1.51514,14.85,0....|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       7.0|\n",
            "|1.51567|13.29|3.45|1.21|72.74|0.56|8.57| 0.0| 0.0|   1|[1.51567,13.29,3....|[0.0,9.5007595602...|[0.0,0.4750379780...|       1.0|\n",
            "+-------+-----+----+----+-----+----+----+----+----+----+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can have the following metrics in multiclass classifition\n",
        "*metricName: pyspark.ml.param.Param[MulticlassClassificationEvaluatorMetricType] = Param(parent='undefined', name='metricName', doc='metric name in evaluation (f1|accuracy|weightedPrecision|weightedRecall|weightedTruePositiveRate| weightedFalsePositiveRate|weightedFMeasure|truePositiveRateByLabel| falsePositiveRateByLabel|precisionByLabel|recallByLabel|fMeasureByLabel| logLoss|hammingLoss)')*"
      ],
      "metadata": {
        "id": "jtuGdefr-HYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluator\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='Type', metricName='accuracy')\n",
        "accuracy = evaluator.evaluate(pred_df)\n",
        "f1 = evaluator.setMetricName('f1').evaluate(pred_df)\n",
        "weightedPrecision = evaluator.setMetricName('weightedPrecision').evaluate(pred_df)\n",
        "weightedRecall = evaluator.setMetricName('weightedRecall').evaluate(pred_df)\n",
        "# precisionByLabel = evaluator.setMetricName('precisionByLabel').evaluate(pred_df)\n",
        "# recallByLabel = evaluator.setMetricName('recallByLabel').evaluate(pred_df)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"f1: {f1}\")\n",
        "print(f\"weightedPrecision: {weightedPrecision}\")\n",
        "print(f\"weightedRecall: {weightedRecall}\")\n",
        "# print(f\"precisionByLabel: {precisionByLabel}\")\n",
        "# print(f\"recallByLabel: {recallByLabel}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwpY2EFO7XyZ",
        "outputId": "938800cc-0e42-455b-e6ce-f4618fc426b2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6779661016949152\n",
            "f1: 0.6804191274506982\n",
            "weightedPrecision: 0.7253771865182483\n",
            "weightedRecall: 0.6779661016949152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Documentation for MulticlassClassification:\n",
        "\n",
        "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.MulticlassClassificationEvaluator.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator.metricName"
      ],
      "metadata": {
        "id": "8r36sKAT-YMn"
      }
    }
  ]
}