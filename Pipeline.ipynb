{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPm+emLZO2VMI9Stj0OlUG/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohandawar/pyspark/blob/main/Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, I am trying to replicate pipelines in pyspark"
      ],
      "metadata": {
        "id": "JOJmj0a4Tlse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmvLe79rUD-6",
        "outputId": "1ede5472-79dc-46ae-f520-17a19c8813d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285398 sha256=e531e2b775edf5f8ed410a86a5764453c2a83f1c047565d9cdbb1d73df98b6f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6ZEaQ0emTh4G"
      },
      "outputs": [],
      "source": [
        "# Import Libs\n",
        "\n",
        "# Pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.tuning import CrossValidator\n",
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Google\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFvSjGBHT8cA",
        "outputId": "62f6187c-028b-440c-f963-882a1f68c7c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start the spark Session\n",
        "spark = SparkSession.builder.appName('Pipeline').getOrCreate()"
      ],
      "metadata": {
        "id": "Jgu0AiG1U7oq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('/content/drive/MyDrive/DataSets_Pyspark_GoogleColab_Primer/Boston.csv', inferSchema=True, header=True).drop('_c0')\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7WQzfAXUe8Z",
        "outputId": "100259ca-b1de-4b91-cb91-122cd1754770"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
            "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|medv|\n",
            "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
            "|0.00632|18.0| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|\n",
            "|0.02731| 0.0| 7.07|   0|0.469|6.421|78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|\n",
            "|0.02729| 0.0| 7.07|   0|0.469|7.185|61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|\n",
            "|0.03237| 0.0| 2.18|   0|0.458|6.998|45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|\n",
            "|0.06905| 0.0| 2.18|   0|0.458|7.147|54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|\n",
            "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train & test split\n",
        "train_df, test_df = df.randomSplit([0.7,0.3], seed=42)"
      ],
      "metadata": {
        "id": "JQnB2mw1U4Qw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list of columns\n",
        "col_list = df.columns\n",
        "\n",
        "# remove the target variable\n",
        "col_list.remove('medv')\n",
        "print('List of Columns to be converted to vec Assemebler: ', col_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hO66VLkVnL7",
        "outputId": "a6c1b045-fdbd-4afc-e442-f70e9e77aa3c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of Columns to be converted to vec Assemebler:  ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instiate the vec assembler\n",
        "vec_assembler = VectorAssembler(inputCols=col_list, outputCol='features')\n",
        "\n",
        "# Instiate the random forest regressor\n",
        "regressor = RandomForestRegressor(labelCol='medv', featuresCol='features')\n",
        "\n",
        "#Start the pipeline\n",
        "pipeline = Pipeline(stages=[vec_assembler, regressor])"
      ],
      "metadata": {
        "id": "14jjgCh6Woz_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the parameter Grid with all parameters\n",
        "paramGrid = ParamGridBuilder()\\\n",
        "            .addGrid(regressor.numTrees,[3,5,10,15])\\\n",
        "            .addGrid(regressor.maxDepth,[3,5,10,15])\\\n",
        "            .build()"
      ],
      "metadata": {
        "id": "YR3Fwc0qZWZO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instiate the evalutor\n",
        "evaluator = RegressionEvaluator(labelCol='medv', metricName='rmse')"
      ],
      "metadata": {
        "id": "CVwHHZuQZ1mI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross Validator Score\n",
        "Crossvalidator = CrossValidator(estimator=pipeline,\n",
        "                                estimatorParamMaps=paramGrid,\n",
        "                                evaluator=evaluator,\n",
        "                                numFolds=10)"
      ],
      "metadata": {
        "id": "X0eFSl_AaHB7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the cross Validator\n",
        "tunned_model = Crossvalidator.fit(train_df)"
      ],
      "metadata": {
        "id": "l_rUmd1iaZy0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "predictions = tunned_model.transform(test_df)\n",
        "\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"RMSE:{rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbobFozRakWA",
        "outputId": "5848950f-90b1-42e1-f455-48fad36c4b63"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE:3.7997402862623955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o9uUCHb1a4PG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}